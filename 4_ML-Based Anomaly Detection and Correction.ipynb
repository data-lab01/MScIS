{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14690c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic \"normal\" sensor data\n",
    "np.random.seed(42)\n",
    "time = np.arange(1000)\n",
    "normal_data = np.sin(0.02 * time) + np.random.normal(0, 0.1, size=time.shape)\n",
    "\n",
    "# Generate corrupted data by injecting anomalies\n",
    "corrupted_data = normal_data.copy()\n",
    "anomaly_indices = np.random.choice(time, size=50, replace=False)\n",
    "corrupted_data[anomaly_indices] += np.random.normal(3, 1, size=anomaly_indices.shape)  # big spikes\n",
    "\n",
    "# Prepare dataset for ML: use past 3 values to predict current value\n",
    "def create_features(data, window=3):\n",
    "    X, y = [], []\n",
    "    for i in range(window, len(data)):\n",
    "        X.append(data[i-window:i])\n",
    "        y.append(data[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Features and labels from corrupted data\n",
    "window_size = 3\n",
    "X_corrupt, y_corrupt = create_features(corrupted_data, window=window_size)\n",
    "X_normal, y_normal = create_features(normal_data, window=window_size)\n",
    "\n",
    "# Train Random Forest on normal data (supervised)\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_normal, y_normal)\n",
    "\n",
    "# Predict values for corrupted data points\n",
    "y_pred = model.predict(X_corrupt)\n",
    "\n",
    "# Detect anomalies where difference between predicted and observed is large\n",
    "errors = np.abs(y_pred - y_corrupt)\n",
    "threshold = 0.5  # anomaly detection threshold\n",
    "anomalies = errors > threshold\n",
    "\n",
    "print(f\"Detected {np.sum(anomalies)} anomalies.\")\n",
    "\n",
    "# Correct corrupted data using model predictions at anomaly points\n",
    "corrected_data = corrupted_data.copy()\n",
    "corrected_data[window_size:] = np.where(anomalies, y_pred, corrupted_data[window_size:])\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(time, normal_data, label='Normal Data')\n",
    "plt.plot(time, corrupted_data, label='Corrupted Data', alpha=0.7)\n",
    "plt.plot(time, corrected_data, label='Corrected Data', linestyle='--')\n",
    "plt.scatter(time[window_size:][anomalies], corrupted_data[window_size:][anomalies], color='red', label='Detected Anomalies')\n",
    "plt.legend()\n",
    "plt.title(\"ML-based Anomaly Detection and Correction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Sensor Value\")\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('/home/rbakyayita/Documents/MScIS-thesis/mscis/MScIS/figures/ml_anomaly_correction.png', dpi=300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4223388",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2dc153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
